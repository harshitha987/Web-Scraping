{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828c95e-2473-41d1-84e6-722c0b649f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to my code! This Python script is designed to scrape cars.com and extract car listings based on various parameters. By inputting specific details, you can customize your search to find the perfect car that meets your requirements.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter The Brand of The Cars (e.g., Lexus) >  BMW\n",
      "Enter The Car Model (Optional) >  \n",
      "Entre Zip Code (Optional) >  \n",
      "Enter The Min Price (Optional) >  \n",
      "Enter The Max Price (Optional) >  \n",
      "How many pages would you like to scrape? >  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete. Data saved in cars.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "print(\"Data of cars\")\n",
    "brand = input(\"Enter The Brand of The Cars (e.g., Lexus) > \")\n",
    "model = input(\"Enter The Car Model (Optional) > \")\n",
    "zip_code = input(\"Entre Zip Code (Optional) > \")\n",
    "min_price = input(\"Enter The Min Price (Optional) > \")\n",
    "max_price = input(\"Enter The Max Price (Optional) > \")\n",
    "how_many_pages = int(input(\"How many pages would you like to scrape? > \"))\n",
    "\n",
    "# Define the main function to perform the scraping\n",
    "def main():\n",
    "    cars_list = []  # Create an empty list to store the scraped data\n",
    "\n",
    "    # Iterate through each page based on the user-provided input\n",
    "    for num in range(1, how_many_pages + 1):\n",
    "        # Construct the URL with the user-provided parameters\n",
    "        url = f\"https://www.cars.com/shopping/results/?stock_type=new&makes%5B%5D=bmw&models%5B%5D=&list_price_max=&maximum_distance=30&zip=60606\"\n",
    "\n",
    "        # Send an HTTP GET request to the URL and retrieve the page content\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Create a BeautifulSoup object to parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "        # Find all the car listings on the page\n",
    "        cars = soup.find_all(\"div\", class_=\"vehicle-details\")\n",
    "\n",
    "        # Extract the desired information from each car listing\n",
    "        for car in cars:\n",
    "            car_name = car.find(\"h2\", class_=\"title\").text.strip()\n",
    "            car_mileage = car.find(\"div\", class_=\"mileage\")\n",
    "            if car_mileage is not None:\n",
    "                car_mileage = car_mileage.text.strip()\n",
    "            car_price = car.find(\"span\", class_=\"primary-price\").text.strip()\n",
    "            car_rating = car.find(\"span\", class_= \"sds-rating__count\").text.strip()\n",
    "            car_review_count = car.find(\"span\", class_=\"sds-rating__link\").text.strip()\n",
    "            car_dealer_name = car.find(\"div\", class_=\"dealer-name\").text.strip()\n",
    "\n",
    "            \n",
    "            #car_rating\n",
    "            #car_review_count\n",
    "            #car_dearler_name\n",
    "            \n",
    "            # Store the extracted data in a dictionary\n",
    "            car_info = {\n",
    "                \"Car Name\": car_name,\n",
    "                \"Car Mileage\": car_mileage,\n",
    "                \"Car Price\": car_price,\n",
    "                \"Car Rating\": car_rating,\n",
    "                \"Car Review Count\": car_review_count,\n",
    "                \"Car Dealer\": car_dealer_name,\n",
    "                \n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the cars_list\n",
    "            cars_list.append(car_info)\n",
    "\n",
    "    # Check if any car listings were found\n",
    "    if cars_list:\n",
    "        keys = cars_list[0].keys()\n",
    "\n",
    "        # Create a CSV file and write the data into it\n",
    "        with open(\"cars_data2.xlsx\", \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(cars_list)\n",
    "\n",
    "        print(\"Scraping complete. Data saved in cars_data2.xlsx\")\n",
    "    else:\n",
    "        print(\"No cars found.\")\n",
    "\n",
    "# Call the main function to initiate the scraping process\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff4382-43f5-4031-ad99-bc1042be4cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210d364-4295-4407-9972-a84224f54687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
